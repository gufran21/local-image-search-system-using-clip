# Local Image Search System using CLIP
This project is a local image search system powered by OpenAI's CLIP (Contrastive Languageâ€“Image Pretraining) model. It allows users to upload a folder of images and query the system with text descriptions. The model then returns the images that best match the provided query, based on semantic similarity.

## Features
- Folder Upload: Upload a folder containing multiple images.
- Text-Based Image Search: Query the uploaded images using descriptive text to find the most relevant images.
- Semantic Similarity: Uses CLIP's vision-language capabilities to match text prompts with images based on their content, rather than just metadata or filenames.
